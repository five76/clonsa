До сих пор наиболее распространенное использование для вытесняемых машин - это рабочие нагрузки больших партий,
когда у вас много рабочих машин, которые обрабатывают небольшую часть общей работы.
Причина проста: вытесняемые машины дешевы, и если одна из этих машин
будет закрыта без предварительного уведомления, задание может завершиться немного медленнее, но не будет
выполнено полностью.
Представьте, что у вас есть работа, которую вы хотите разделить на четыре части. Вы можете использовать
обычную виртуальную машину для управления процессом, а затем четыре виртуальные машины с возможностью вытеснения для выполнения работы. Около
при этом любой из фрагментов может быть отменен в любой момент, но вы можете повторить
этот фрагмент работы на другой вытесняемой виртуальной машине. Делая это, вы можете использовать более дешевые
вычислительные мощности для работы на работе. В обмен на ваши сбережения рабочие
(Виртуальные машины) могут быть убиты и нуждаться в замене (рис. 9.33). После того, как я обсудил, почему существуют вытесняемые машины и для чего они хороши,
следующий очевидный вопрос заключается в том, как все это работает? Чтобы понять это, давайте рассмотрим
две новые вещи, о которых вам нужно подумать: включение машин как упреждающих и
обработка запросов на завершение работы машин.
9.4.2
Включение вытесняемых виртуальных машин
Создать виртуальную машину с возможностью вытеснения очень просто. При создании виртуальной машины (или шаблона
экземпляра) в разделе “Дополнительно” (ссылка с надписью "Управление, диски,
сеть, ключи SSH") (рис. 9.34) в разделе "Политика доступности" вы заметите, что в разделе "Политика доступности
" можно задать возможность преимущественной загрузки. Изменение этого параметра с "Выключено" на "Включено" делает вашу виртуальную машину недоступной.Как вы догадываетесь, это сопровождается побочным эффектом, заключающимся в том, что отключаются как автоматические перезапуски, так и мигрирование в реальном времени во
время обслуживания хоста. Это не должно быть проблемой, потому что
при проектировании для вытесняемых машин вы уже ожидаете, что машина
может исчезнуть в любой момент. Теперь, когда вы понимаете, как создать упреждающую
машину, давайте перейдем к концу ее срока службы и посмотрим, как справиться с
неизбежным прекращением работы GCE.Вытесняемые машины могут быть отключены в любое время (и, безусловно, будут отключены
в течение 24 часов), и понимание того, как изящно обрабатывать эти отключения
, критически важно. К счастью, GCE не подкрадывается к вам с этим, а вместо этого
предоставляет вам разумное окно уведомления, чтобы вы знали, что оно завершит работу вашей
виртуальной машины. Вы можете прослушать это уведомление и завершить любую незавершенную работу до того, как виртуальная
машина исчезнет.Самый простой способ прослушать его — установить сценарий завершения работы - нечто противоположное
тому, что вы делали со сценариями запуска ваших шаблонов экземпляров. После
завершения работы GCE дает виртуальной машине 30 секунд на завершение работы, а затем посылает четкий
сигнал завершения (эквивалент нажатия кнопки питания вашего устройства) и переключает
машина остановлена. Это дает вашему сценарию завершения работы 30 секунд на выполнение своей работы.
Через 30 секунд вилку выдергивают.
Чтобы задать сценарий завершения работы, вы можете использовать раздел метаданных экземпляра (или
шаблон экземпляра) с ключом, соответствующим образом называемым сценарий завершения работы (рис. 9.35).Если у вас есть сценарий завершения работы, хранящийся удаленно в облачном хранилище, вы можете связать его с помощью
метаданных с ключом shutdown-script-url и URL, начинающимся с gs:// (рис. 9.36). Выбор упреждающего
При выборе виртуальной машины для завершения работы GCE выбирает самую молодую, которая может показаться
нелогично. Чтобы понять, почему это происходит, давайте подумаем о
том, какой наилучший вариант для завершения виртуальной машины.
Представьте, что у вас есть задание, где каждой виртуальной машине необходимо загрузить большой (5 ГБ) файл. Если
вы загрузите свои виртуальные машины по порядку, и они сразу приступят к загрузке файла, в любой момент времени у первой виртуальной машины будет больше прогресса загрузки, чем у второй, третьей и
четвертой. Теперь представьте, что Google необходимо закрыть одну из этих виртуальных машин. Какой из
них наиболее удобен для завершения? Какая виртуальная машина вызывает наименьшее количество потраченной впустую работы, если она
должен быть прекращен и начат заново? Очевидно, что это тот, который запустился последним и
загрузил наименьшее количество данных (рис. 9.37).Поскольку GCE завершит работу самой молодой машины, одна из проблем заключается в том, что
машины постоянно прекращают работу и никогда не добиваются никакого прогресса. Хотя это
определенно возможно, GCE будет равномерно распределять прекращения на глобальном уровне. Если он хочет
вернуть 100 виртуальных машин, он заберет эти 100 у множества клиентов, а не у
одного. В результате вы должны видеть повторные прерывания только во время экстремальных кругов-
позиции. В редких случаях, когда происходит сбой, помните, что GCE не
взимает плату за виртуальные машины, которые принудительно завершаются в течение первых 10 минут. Рассмотрев этот последний
аспект эфемерных вычислений, давайте рассмотрим, как сбалансировать запросы на
нескольких компьютерах с помощью балансировщика нагрузки.Балансировка нагрузки
Балансировка нагрузки - относительно старая тема, поэтому, если вы запускали какое-либо крупное веб-
приложение, вы, вероятно, по крайней мере знакомы с этой концепцией. Основной принцип заключается
в том, что иногда общий трафик, который вам необходимо обработать во всей вашей системе, составляет
слишком много для одной машины. В результате, вместо того, чтобы сделать ваши автоматы больше
и больше, чтобы обрабатывать трафик, можно использовать больше машин и полагаться на балансировщик нагрузки
в Сплит (баланс) движения (нагрузки) через имеющиеся ресурсы (рис. 9.38).Традиционно, если вам нужен балансировщик нагрузки (а вы не обращаетесь много миллионов
попаданий в секунду), вы бы включить виртуальную машину и установить программное обеспечение для балансировки нагрузки,
это может быть что угодно от HAProxy кальмарами или даже с nginx. Но поскольку это
такая распространенная практика, облачная платформа Google предлагает полностью управляемый балансировщик нагрузки
это делает все то, что могут делать традиционные программные балансировщики нагрузки.
Поскольку балансировщики нагрузки принимают входящие запросы спереди и распределяют их
по некоторому набору машин сзади, любой балансировщик нагрузки будет иметь как внешние
, так и внутренние конфигурации. Эти конфигурации определяют, как балансировщик нагрузки будет
прослушивать новые запросы и куда он будет отправлять эти запросы по мере их поступления. Эти
конфигурации могут варьироваться от суперпростых до чрезвычайно сложных. Простой
пример поможет вам лучше понять, как все это работает.
Представьте, что у вас есть веб-приложение калькулятора, которое позволяет пользователям вводить вычисления
в поле, скажем, 2 + 2, а затем приложение выводит правильный ответ —
в данном случае 4. Этот калькулятор не так уж полезен, но важно отметить, что ему
не нужно ничего хранить, поэтому вы говорите, что он не имеет состояния.
Теперь представьте, что по какой-то причине калькулятор стал настолько популярным, что
одна виртуальная машина, обрабатывающая вычисления, перегружена трафиком. В этом сценарии вы создали
бы вторую виртуальную машину, работающую с тем же программным обеспечением, что и первая; затем вы создали бы нагрузку
балансировщик для равномерного распределения трафика между двумя машинами (рис. 9.39). Интерфейс балансировщика нагрузки будет прослушивать HTTP-трафик и перенаправлять все запросы на серверную
часть, состоящую из двух виртуальных машин, которые обрабатывают вычисления. После завершения вычисления
виртуальные машины выдают результат, и балансировщик нагрузки пересылает ответ
обратно по соединению, используемому для отправки запроса.
Важно отметить, что виртуальные машины понятия не имеют о том, что задействован балансировщик нагрузки,
потому что, с их точки зрения, поступают запросы и отправляются ответы, поэтому нагрузка
балансировщик выглядит так же, как любой другой клиент, делающий запросы. И самая удобная часть
всего этого заключается в том, что по мере увеличения трафика вы можете включить другую виртуальную машину и настроить
серверную часть балансировщика нагрузки, чтобы также отправлять запросы на новую виртуальную машину. Если бы вы хотели
автоматизировать это еще больше, вы могли бы настроить балансировщик нагрузки на использование группы
экземпляров автоматического масштабирования для его серверной части, чтобы вам не пришлось беспокоиться о добавлении новой
емкости и регистрации ее в балансировщике нагрузки.
Давайте рассмотрим процесс настройки балансировщика нагрузки и разделения трафика
через несколько виртуальных машин. Для этого вы перепрофилируете группу экземпляров виртуальной машины, о которой вы узнали
в разделе 9.4, в качестве серверной части вашего балансировщика нагрузки. Чтобы создать балансировщик нагрузки,
выберите Сетевые службы в левой части навигации в облачной консоли, а
затем выберите Балансировку нагрузки. На этой странице вы должны увидеть приглашение,
позволяющее создать новый балансировщик нагрузки, нажав кнопку.
Когда вы нажмете, чтобы создать новый балансировщик нагрузки, вы увидите несколько вариантов типов
балансировки нагрузки, которые вы можете выполнить. Для этого упражнения вы будете использовать балансировку нагрузки HTTP(S)
потому что вы пытаетесь сбалансировать HTTP-запросы в своем веб-приложении.
Нажмите кнопку "Начать настройку", и вы увидите новую страницу, на которой можно выбрать
имя (используйте первый балансировщик нагрузки) и три шага к настройке нового балансировщика
нагрузки: конфигурация серверной части, Правила хоста и пути и Конфигурация интерфейса.
Поскольку вы хотите настроить балансировщик нагрузки для приема HTTP-запросов и отправки их
в вашу группу экземпляров в качестве серверной части, начните с настройки конфигурации серверной части. Конфигурация серверной части
Первое, что вам нужно сделать, это создать так называемую серверную службу. Эта услуга
представляет коллекцию серверных компонентов (типичных виртуальных машин, работающих в GCE), которые в настоящее время относятся
только к группам экземпляров. Для этого щелкните раскрывающийся список с надписью Создать или Выберите
Бэкенд-сервисы и Бэкенд-пакеты. Оттуда выберите Серверные службы > Создать
серверную службу, которая откроет новую форму, в которой вы можете настроить свою новую службу
(рис. 9.40).
ПРИМЕЧАНИЕ. Вам может быть интересно, почему у вас есть этот дополнительный уровень косвенности и
почему вам нужно создать службу, содержащую одну группу экземпляров. Простой
ответ заключается в том, что, хотя сейчас у вас есть только одна группа экземпляров, вы
возможно, позже потребуется добавить дополнительные группы за балансировщиком нагрузки.
Серверные службы позволяют балансировщику нагрузки всегда указывать на одну вещь, чтобы вы
могли добавлять серверные части (группы экземпляров) в службу и удалять их из нее.
